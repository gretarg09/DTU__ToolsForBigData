{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Read the image, convert it into grayscale, and make in binary image for threshold value of 1.\n",
    "img = cv2.imread('frame.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#Now find contours in it. There will be only one object, so find bounding rectangle for it.\n",
    "\n",
    "contours = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = contours[0]\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "#Now crop the image, and save it into another file.\n",
    "\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('framemod.png',crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def autocrop(image, threshold=0):\n",
    "    \"\"\"Crops any edges below or equal to threshold\n",
    "\n",
    "    Crops blank image to 1x1.\n",
    "\n",
    "    Returns cropped image.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        flatImage = np.max(image, 2)\n",
    "    else:\n",
    "        flatImage = image\n",
    "    assert len(flatImage.shape) == 2\n",
    "\n",
    "    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n",
    "    if rows.size:\n",
    "        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n",
    "        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n",
    "    else:\n",
    "        image = image[:1, :1]\n",
    "\n",
    "    return image\n",
    "\n",
    "img = cv2.imread('frame.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "crop = autocrop(gray)\n",
    "cv2.imwrite('framemodOther.png',crop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crop_image(img,tol=0):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "img = cv2.imread('frame.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "crop = autocrop(gray)\n",
    "cv2.imwrite('framemodThird.png',crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread('histogramNormalization/first.png',0)\n",
    "img2 = cv2.imread('histogramNormalization/second.png',0)\n",
    "# Equalization\n",
    "#img = cv2.imread('wiki.jpg',0)\n",
    "equ1 = cv2.equalizeHist(img1)\n",
    "equ2 = cv2.equalizeHist(img2)\n",
    "res = np.hstack((equ1,equ2)) #stacking images side-by-side\n",
    "cv2.imwrite('histogramNormalization/res.png',res)\n",
    "\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(img1)\n",
    "cl2 = clahe.apply(img2)\n",
    "res_cl = np.hstack((cl1, cl2)) #stacking images side-by-side\n",
    "cv2.imwrite('histogramNormalization/res_cl.png',res_cl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itertools combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('0WS86GPURFK5', 'c68686868e0f0e1c'), ('76KUS3QCGVCY', 'c78786868e0f0e1c'))\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# key value pair (key, value)\n",
    "\n",
    "example_hash_strings= [(\"0WS86GPURFK5\",\"c68686868e0f0e1c\"), \n",
    "                    (\"76KUS3QCGVCY\",\"c78786868e0f0e1c\") ,\n",
    "                    (\"96EC4QS20Z28\",\"c78786868e0f0e1c\"),\n",
    "                    (\"CL8W7L333U90\",\"c78706868e0f0e1c\"),\n",
    "                    (\"FDAZ5NL5NFL2\",\"c7870646ce0f0e1c\"),\n",
    "                    (\"HBX8QLI9HH25\",\"c7870686ce0f0e1c\"),\n",
    "                    (\"JY2ZAINWD2RX\",\"c68706068e0e0e1c\"),\n",
    "                    (\"LP47ZGJ256YU\",\"c78786068e0f0e1e\"),\n",
    "                    (\"NTETO8P77N96\",\"c78786868e0f0e1c\"),\n",
    "                    (\"SLK2PRXGW3DZ\",\"c78706868e0f0e1c\")]\n",
    "\n",
    "example_hash_strings2= [(\"0WS86GPURFK5\",\"c68686868e0f0e1c\"), \n",
    "                    (\"76KUS3QCGVCY\",\"c78786868e0f0e1c\") ]\n",
    "\n",
    "# find all combinations\n",
    "for i in combinations(example_hash_strings2, 2):\n",
    "    # calculate difference in hash for each pair\n",
    "    print i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0WS86GPURFK5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
