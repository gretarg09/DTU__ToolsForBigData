{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 10.1 Feature Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path_to_folder = \"/Users/GretarAtli/Documents/GitHub/Dtu/Dtu-ToolsForBigData/week_10/ex10/data\"\n",
    "name = '/reuters-'\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        if i== 2 and j > 1:\n",
    "            break\n",
    "    \n",
    "        file_paths.append(path_to_folder  + name + '0' + str(i) + str(j) + '.json')   \n",
    "\n",
    "topics = []\n",
    "bodies = []\n",
    "\n",
    "# Read in the data\n",
    "for path in file_paths:\n",
    "    with open(path) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        for di in d:\n",
    "            try:\n",
    "                topic = di['topics']\n",
    "                body = di['body']\n",
    "                # Check if earn is part of the topics\n",
    "                if \"earn\" in topic:\n",
    "                    topics.append(1)\n",
    "                else:\n",
    "                    topics.append(0)\n",
    "                bodies.append(body)\n",
    "            except:\n",
    "                pass\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.96676300578\n",
      "The score with .score function =0.96676300578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create raw bag-of-words encoding.\n",
    "cv = CountVectorizer(stop_words=\"english\", lowercase=True)\n",
    "bag_of_words_matrix = cv.fit_transform(bodies)\n",
    "bag_of_words_matrix.toarray()\n",
    "\n",
    "# Split the data into training and testing set\n",
    "x_train,x_test,y_train,y_test = train_test_split( bag_of_words_matrix, topics, test_size=0.2)\n",
    "\n",
    "# Now we are ready to use the random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicte = clf.predict(x_test)\n",
    "\n",
    "# Report the score\n",
    "print (\"The score is {}\".format(\n",
    "    np.sum( np.array(y_test) == np.array(y_predicte) ) / len(np.array(y_test))\n",
    "    ))\n",
    "\n",
    "print (\"The score with .score function ={}\".format(\n",
    "        clf.score(x_test,y_test)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.93063583815\n"
     ]
    }
   ],
   "source": [
    "# Now we implement feature hashing and use 1000 buckets instead of the raw bag-of-words encoding.\n",
    "\n",
    "# First we implement the hashing vectorizer\n",
    "def hashing_vectorizer(features, N):\n",
    "    x = np.zeros(N)\n",
    "    for f in features:\n",
    "        h = hash(f)\n",
    "        x[h % N] += 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "# initialize the feature hashing matrix\n",
    "N = 1000 # number of buckets\n",
    "feature_hasing_matrix = np.zeros((len(bodies), N))\n",
    "\n",
    "for i,_ in enumerate(feature_hasing_matrix):\n",
    "    feature_hasing_matrix[i] = hashing_vectorizer(bodies[i],N)\n",
    "    \n",
    "# know we use this matrix to train our machine learning algorithm\n",
    "\n",
    "# Split the data into training and testing set\n",
    "x_train,x_test,y_train,y_test = train_test_split( feature_hasing_matrix, topics, test_size=0.2)\n",
    "\n",
    "# Now we are ready to use the random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicte = clf.predict(x_test)\n",
    "\n",
    "# Report the score\n",
    "print (\"The score is {}\".format(\n",
    "    np.sum( np.array(y_test) == np.array(y_predicte) ) / len(np.array(y_test))\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10.2 (LSH)\n",
    "Implement the LSH algorithm from the lecture to hash images (so that similar images get similar hashes). Show that it works with an example or two.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open('cat.png').convert('LA')\n",
    "img = img.resize((9,8))\n",
    "img.save('cat_greyscaleless.png')\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "img_rednose = Image.open('cat_rednose.png').convert('LA')\n",
    "img_rednose = img.resize((9,8))\n",
    "img_rednose.save('cat_greyscaleless_rednose.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 02 07 00 82 31 4b 03\n"
     ]
    }
   ],
   "source": [
    "import cv2 # for this I needed to install opencv -> pip install opencv-python\n",
    "\n",
    "# Grayscale the image\n",
    "img = cv2.imread('cat_mod_more.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Resize to 9x8 pixels\n",
    "img = cv2.resize(img,(9,8))\n",
    "\n",
    "# Compare adjacent values (x>y)\n",
    "\n",
    "img_compared = np.empty((8,8))\n",
    "\n",
    "for i,row in enumerate(img):\n",
    "    for j,column in enumerate(row):\n",
    "        if j + 1 == len(row):\n",
    "            break\n",
    "        else:\n",
    "            img_compared[i][j] = row[j] > row[j+1]\n",
    "\n",
    "\n",
    "for difference in img_compared:\n",
    "    decimal_value = 0\n",
    "    hex_string = []\n",
    "    for index, value in enumerate(difference):\n",
    "        if value:\n",
    "            decimal_value += 2**(index % 8)\n",
    "        if (index % 8) == 7:\n",
    "            hex_string.append(hex(decimal_value)[2:].rjust(2, '0'))\n",
    "            decimal_value = 0\n",
    "    print ''.join(hex_string),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer for cat          = 14 02 07 00 82 31 4b 03\n",
    "\n",
    "answer for cat mod      = 14 02 07 00 82 31 4b 03\n",
    "\n",
    "answer for cat mod more = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4c 26 13 89 c4 62 31 98\n"
     ]
    }
   ],
   "source": [
    "differences = [[False, False, True, True, False, False, True, False],[False, True, True, False, False, True, False, False],[True, True, False, False, True, False, False, False],[True, False, False, True, False, False, False, True],[False, False, True, False, False, False, True, True],[False, True, False, False, False, True, True, False],[True, False, False, False, True, True, False, False],[False, False, False, True, True, False, False, True]]\n",
    "for difference in differences:\n",
    "\tdecimal_value = 0\n",
    "\thex_string = []\n",
    "\tfor index, value in enumerate(difference):\n",
    "\t\tif value:\n",
    "\t\t\tdecimal_value += 2**(index % 8)\n",
    "\t\tif (index % 8) == 7:\n",
    "\t\t\thex_string.append(hex(decimal_value)[2:].rjust(2, '0'))\n",
    "\t\t\tdecimal_value = 0\n",
    "\tprint ''.join(hex_string),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
