{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 10.1 Feature Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path_to_folder = \"/Users/GretarAtli/Documents/GitHub/Dtu/Dtu-ToolsForBigData/week_10/ex10/data\"\n",
    "name = '/reuters-'\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        if i== 2 and j > 1:\n",
    "            break\n",
    "    \n",
    "        file_paths.append(path_to_folder  + name + '0' + str(i) + str(j) + '.json')   \n",
    "\n",
    "topics = []\n",
    "bodies = []\n",
    "\n",
    "# Read in the data\n",
    "for path in file_paths:\n",
    "    with open(path) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        for di in d:\n",
    "            try:\n",
    "                topic = di['topics']\n",
    "                body = di['body']\n",
    "                # Check if earn is part of the topics\n",
    "                if \"earn\" in topic:\n",
    "                    topics.append(1)\n",
    "                else:\n",
    "                    topics.append(0)\n",
    "                bodies.append(body)\n",
    "            except:\n",
    "                pass\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.971579961464\n",
      "The score with .score function =0.971579961464\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create raw bag-of-words encoding.\n",
    "cv = CountVectorizer(stop_words=\"english\", lowercase=True)\n",
    "bag_of_words_matrix = cv.fit_transform(bodies)\n",
    "bag_of_words_matrix.toarray()\n",
    "\n",
    "# Split the data into training and testing set\n",
    "x_train,x_test,y_train,y_test = train_test_split( bag_of_words_matrix, topics, test_size=0.2)\n",
    "\n",
    "# Now we are ready to use the random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicte = clf.predict(x_test)\n",
    "\n",
    "# Report the score\n",
    "print (\"The score is {}\".format(\n",
    "    np.sum( np.array(y_test) == np.array(y_predicte) ) / len(np.array(y_test))\n",
    "    ))\n",
    "\n",
    "print (\"The score with .score function ={}\".format(\n",
    "        clf.score(x_test,y_test)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is 0.93063583815\n"
     ]
    }
   ],
   "source": [
    "# Now we implement feature hashing and use 1000 buckets instead of the raw bag-of-words encoding.\n",
    "\n",
    "# First we implement the hashing vectorizer\n",
    "def hashing_vectorizer(features, N):\n",
    "    x = np.zeros(N)\n",
    "    for f in features:\n",
    "        h = hash(f)\n",
    "        x[h % N] += 1\n",
    "        \n",
    "    return x\n",
    "\n",
    "# initialize the feature hashing matrix\n",
    "N = 1000 # number of buckets\n",
    "feature_hasing_matrix = np.zeros((len(bodies), N))\n",
    "\n",
    "for i,_ in enumerate(feature_hasing_matrix):\n",
    "    feature_hasing_matrix[i] = hashing_vectorizer(bodies[i],N)\n",
    "    \n",
    "# know we use this matrix to train our machine learning algorithm\n",
    "\n",
    "# Split the data into training and testing set\n",
    "x_train,x_test,y_train,y_test = train_test_split( feature_hasing_matrix, topics, test_size=0.2)\n",
    "\n",
    "# Now we are ready to use the random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(x_train, y_train)\n",
    "y_predicte = clf.predict(x_test)\n",
    "\n",
    "# Report the score\n",
    "print (\"The score is {}\".format(\n",
    "    np.sum( np.array(y_test) == np.array(y_predicte) ) / len(np.array(y_test))\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Showers continued throughout the week in\\nthe Bahia cocoa zone, alleviating the drought since early\\nJanuary and improving prospects for the coming temporao,\\nalthough normal humidity levels have not been restored,\\nComissaria Smith said in its weekly review.\\n    The dry period means the temporao will be late this year.\\n    Arrivals for the week ended February 22 were 155,221 bags\\nof 60 kilos making a cumulative total for the season of 5.93\\nmln against 5.81 at the same stage last year. Again it seems\\nthat cocoa delivered earlier on consignment was included in the\\narrivals figures.\\n    Comissaria Smith said there is still some doubt as to how\\nmuch old crop cocoa is still available as harvesting has\\npractically come to an end. With total Bahia crop estimates\\naround 6.4 mln bags and sales standing at almost 6.2 mln there\\nare a few hundred thousand bags still in the hands of farmers,\\nmiddlemen, exporters and processors.\\n    There are doubts as to how much of this cocoa would be fit\\nfor export as shippers are now experiencing dificulties in\\nobtaining +Bahia superior+ certificates.\\n    In view of the lower quality over recent weeks farmers have\\nsold a good part of their cocoa held on consignment.\\n    Comissaria Smith said spot bean prices rose to 340 to 350\\ncruzados per arroba of 15 kilos.\\n    Bean shippers were reluctant to offer nearby shipment and\\nonly limited sales were booked for March shipment at 1,750 to\\n1,780 dlrs per tonne to ports to be named.\\n    New crop sales were also light and all to open ports with\\nJune/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\\nunder New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\\nper tonne FOB.\\n    Routine sales of butter were made. March/April sold at\\n4,340, 4,345 and 4,350 dlrs.\\n    April/May butter went at 2.27 times New York May, June/July\\nat 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\\n2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\\n2.27 times New York Dec, Comissaria Smith said.\\n    Destinations were the U.S., Covertible currency areas,\\nUruguay and open ports.\\n    Cake sales were registered at 785 to 995 dlrs for\\nMarch/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\\nNew York Dec for Oct/Dec.\\n    Buyers were the U.S., Argentina, Uruguay and convertible\\ncurrency areas.\\n    Liquor sales were limited with March/April selling at 2,325\\nand 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\\nYork July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\\nSept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\\nsaid.\\n    Total Bahia sales are currently estimated at 6.13 mln bags\\nagainst the 1986/87 crop and 1.06 mln bags against the 1987/88\\ncrop.\\n    Final figures for the period to February 28 are expected to\\nbe published by the Brazilian Cocoa Trade Commission after\\ncarnival which ends midday on February 27.\\n Reuter\\n\\x03'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bla=np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla[1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
